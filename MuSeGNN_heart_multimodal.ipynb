{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5b316837-2a44-4e18-b53f-6f24abb9173b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch_geometric.nn\n",
    "import torch_geometric.data as data\n",
    "import networkx as nx\n",
    "from torch_geometric.utils.convert import to_networkx\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import scanpy as sc\n",
    "import pandas as pd\n",
    "import random\n",
    "import argparse\n",
    "\n",
    "\n",
    "from torch_geometric.nn import TransformerConv\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4f44ae2a-5280-4a40-9626-85380362e8b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1/(1+np.exp(-x))\n",
    "\n",
    "def set_seed(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    os.environ['PYTHONHASHEED'] = str(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "\n",
    "def parse_args():\n",
    "    parser = argparse.ArgumentParser(description='Run encoder')\n",
    "\n",
    "    parser.add_argument('--epoches', type=int, default=2000,\n",
    "                        help='number of epoches')\n",
    "    parser.add_argument('--lambdac', type=float, default=0.01,\n",
    "                        help='weight for the contrastive learning') \n",
    "    parser.add_argument('--lr1', type=float, default=1e-4,\n",
    "                        help='lr for encoder')     \n",
    "    parser.add_argument('--lr2', type=float, default=1e-3,\n",
    "                        help='lr for decoder')\n",
    "    parser.add_argument('--temp', type=float, default=0.07,\n",
    "                        help='temperature for the contrastive learning') \n",
    "    parser.add_argument('--samplesize', type=int, default=100,\n",
    "                        help='sample size for contrastive learning')\n",
    "    parser.add_argument('--dim', type=float, default=32,\n",
    "                        help='latent dimensions') \n",
    "    parser.add_argument('--savepath', type=str, default=\"heart_global/heart_umi_m_musegnn.h5ad\",\n",
    "                        help='save path') \n",
    "    \n",
    "    \n",
    "    return parser.parse_args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c25ed5d4-9078-4ac3-9f6f-dd695b8fab2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(epoches=3, lambdac=0.01, lr1=0.0001, lr2=0.001, temp=0.07, samplesize=100, dim=32.0, savepath='heart_umi_m_musegnn.h5ad')\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import torch\n",
    "import argparse\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "#set_seed(0)\n",
    "\n",
    "# # for specific encoder/decoder\n",
    "# # tissue_list = { \n",
    "# #                \"heart\":[233, 676, 783, 947,266, 223, 233, 978, 928, 852, 839, 733]}\n",
    "sys.argv = [\n",
    "    'script_name',  # The first element is the script name, can be any name.\n",
    "    '--epoches', '3',\n",
    "    '--lambdac', '0.01',\n",
    "    '--lr1', '1e-4',\n",
    "    '--lr2', '1e-3',\n",
    "    '--temp', '0.07',\n",
    "    '--samplesize', '100',\n",
    "    '--dim', '32',\n",
    "    '--savepath', 'heart_umi_m_musegnn.h5ad'\n",
    "]\n",
    "\n",
    "# Now, you can call your function and parse the arguments\n",
    "args = parse_args()\n",
    "\n",
    "# Display the arguments to confirm that they are parsed correctly\n",
    "print(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "56cb2c3f-afc0-4826-a27a-5590497fe8b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "tissue_list = {\"heart\":['rna', \"spatial\"]}\n",
    "\n",
    "# construct graph batch\n",
    "# based on simulation results\n",
    "graph_list = []\n",
    "cor_list = []\n",
    "label_list = []\n",
    "graph_networkx_list = []\n",
    "count = 0\n",
    "gene_length = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b140b6e7-265b-419f-8f85-dd290ae8f2ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'heart': ['rna', 'spatial']}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tissue_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1c06db3b-8e10-4f66-b657-d4c949b37e0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rna\n",
      "(1000, 1000)\n",
      "(1000, 5000)\n",
      "spatial\n",
      "(1000, 1000)\n",
      "(1000, 5000)\n"
     ]
    }
   ],
   "source": [
    "for tissue in tissue_list.keys():\n",
    "    for i in tissue_list[tissue]:\n",
    "        print(i)\n",
    "        #pathway_count = \"/projectnb/cs598/projects/singleCell/data/heart_spatial_expression.csv\"\n",
    "        #pathway_matrix = \"/projectnb/cs598/projects/singleCell/data/heart_spatial_pvalue.csv\"\n",
    "        pathway_count = \"/projectnb/cs598/projects/singleCell/data/heart_\" + i + \"_expression.csv\"\n",
    "        pathway_matrix = \"/projectnb/cs598/projects/singleCell/data/heart_\" + i + \"_pvalue.csv\"\n",
    "\n",
    "        pd_adata_new =  pd.read_csv(pathway_count, index_col=0)\n",
    "        correlation = pd.read_csv(pathway_matrix, index_col=0)\n",
    "        cor_list.append(correlation)\n",
    "\n",
    "        print(correlation.shape)\n",
    "        print(pd_adata_new.shape)\n",
    "        adata = sc.AnnData(pd_adata_new)\n",
    "        gene_length = len(adata)\n",
    "\n",
    "        adata_new = adata.copy()\n",
    "        edges_new = np.array([np.nonzero(correlation.values)[0],np.nonzero(correlation.values)[1]])\n",
    "        graph = data.Data(x=torch.FloatTensor(adata_new.X.copy()), edge_index=torch.FloatTensor(edges_new).long())\n",
    "        \n",
    "        vis = nx.from_pandas_adjacency(correlation)\n",
    "        graph_networkx_list.append(vis)\n",
    "        \n",
    "        graph.gene_list = pd_adata_new.index\n",
    "        graph.show_index = tissue +\"__\" + str(i)\n",
    "        \n",
    "        graph_list.append(graph)\n",
    "        label_list.append(tissue)\n",
    "        \n",
    "        count +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "025d386f-33e5-419a-8be4-8a4fada5cfb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GCNEncoder_Multiinput(torch.nn.Module):\n",
    "    def __init__(self, out_channels, graph_list, label_list):\n",
    "        super(GCNEncoder_Multiinput, self).__init__()\n",
    "        self.activ = nn.Mish(inplace=True)\n",
    "        \n",
    "        conv_dict = {}\n",
    "        conv_dict1 = {}\n",
    "        for i in graph_list:\n",
    "            conv_dict[i.show_index] = torch_geometric.nn.Sequential('x, edge_index', [(TransformerConv(i.x.shape[1], out_channels, heads=4),'x, edge_index-> x'),\n",
    "                                                     (torch_geometric.nn.GraphNorm(out_channels*4), 'x -> x')])\n",
    "        self.convl1 = nn.ModuleDict(conv_dict)\n",
    "        self.convl2 = nn.ModuleDict(conv_dict1)\n",
    "              \n",
    "    def forward(self, x, edge_index, show_index):\n",
    "        x = self.convl1[show_index](x, edge_index)\n",
    "        x = self.activ(x)\n",
    "        return x\n",
    "    \n",
    "class GCNEncoder_Commoninput(torch.nn.Module):\n",
    "    def __init__(self, out_channels, graph_list, label_list):\n",
    "        super(GCNEncoder_Commoninput, self).__init__()\n",
    "        self.activ = nn.Mish(inplace=True)\n",
    "        \n",
    "        conv_dict_l2 = {}\n",
    "        conv_dict_l3 = {}\n",
    "        conv_dict_l4 = {}\n",
    "        tissue_specific_list = list(set(label_list))\n",
    "        \n",
    "        for i in tissue_specific_list:\n",
    "            conv_dict_l2[i] = torch_geometric.nn.Sequential('x, edge_index', [(TransformerConv(out_channels*4, out_channels, heads=2),'x, edge_index -> x'),\n",
    "                                                     (torch_geometric.nn.GraphNorm(out_channels*2), 'x -> x')])\n",
    "            conv_dict_l3[i] = TransformerConv(out_channels*2, out_channels)\n",
    "            conv_dict_l4[i] = TransformerConv(out_channels*4, out_channels)\n",
    "              \n",
    "        self.convl2 = nn.ModuleDict(conv_dict_l2)\n",
    "        self.convl3 = nn.ModuleDict(conv_dict_l3)\n",
    "        self.convl4 = nn.ModuleDict(conv_dict_l4)\n",
    "        \n",
    "    def forward(self, x, edge_index, show_index):\n",
    "        x_inp = x\n",
    "        x = self.convl2[show_index.split('__')[0]](x, edge_index)\n",
    "        x = self.activ(x)\n",
    "        x = self.convl3[show_index.split('__')[0]](x, edge_index)\n",
    "        return x + self.convl4[show_index.split('__')[0]](x_inp, edge_index)\n",
    "\n",
    "class MLP_edge_Decoder(torch.nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, graph_list):\n",
    "        super(MLP_edge_Decoder, self).__init__()\n",
    "        \n",
    "        dec_dict = {}\n",
    "        \n",
    "        self.activ = nn.Mish(inplace=True)\n",
    "        for i in graph_list:\n",
    "            dec_dict[i.show_index] = torch.nn.Sequential(\n",
    "                                              nn.Linear(in_channels,  out_channels)\n",
    "                                             , self.activ,\n",
    "                                              nn.Linear(in_channels,  out_channels)\n",
    "                                             , self.activ,\n",
    "                                              nn.Linear(in_channels,  out_channels)\n",
    "                                             )\n",
    "        self.MLP = nn.ModuleDict(dec_dict)\n",
    "        \n",
    "    def forward(self, x, show_index):\n",
    "        x = self.MLP[show_index](x)\n",
    "        return x\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bcb02e1d-80a9-4904-bda5-c8184bd86e7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Data(x=[1000, 5000], edge_index=[2, 311364], gene_list=Index(['ENSG00000187608', 'ENSG00000171621', 'ENSG00000162444',\n",
       "        'ENSG00000175206', 'ENSG00000120937', 'ENSG00000189337',\n",
       "        'ENSG00000231606', 'ENSG00000188257', 'ENSG00000173372',\n",
       "        'ENSG00000159189',\n",
       "        ...\n",
       "        'ENSG00000154734', 'ENSG00000156273', 'ENSG00000156299',\n",
       "        'ENSG00000159216', 'ENSG00000157554', 'ENSG00000198888',\n",
       "        'ENSG00000198899', 'ENSG00000198840', 'ENSG00000198886',\n",
       "        'ENSG00000198727'],\n",
       "       dtype='object', length=1000), show_index='heart__rna'),\n",
       " Data(x=[1000, 5000], edge_index=[2, 206998], gene_list=Index(['ENSG00000188290', 'ENSG00000187608', 'ENSG00000162576',\n",
       "        'ENSG00000179403', 'ENSG00000197785', 'ENSG00000189409',\n",
       "        'ENSG00000235169', 'ENSG00000116285', 'ENSG00000074800',\n",
       "        'ENSG00000171819',\n",
       "        ...\n",
       "        'ENSG00000159200', 'ENSG00000185437', 'ENSG00000157601',\n",
       "        'ENSG00000160214', 'ENSG00000160255', 'ENSG00000182871',\n",
       "        'ENSG00000142156', 'ENSG00000142173', 'ENSG00000228253',\n",
       "        'ENSG00000212907'],\n",
       "       dtype='object', length=1000), show_index='heart__spatial')]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b558b2fb-63d3-46b8-9e40-1e1f52abe8af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finish preprocessing\n",
      "start training\n"
     ]
    }
   ],
   "source": [
    "gene_encoder_is = GCNEncoder_Multiinput(int(args.dim), graph_list, label_list).to(device)\n",
    "gene_encoder_com =  GCNEncoder_Commoninput(int(args.dim), graph_list, label_list).to(device)\n",
    "\n",
    "gene_decoder = MLP_edge_Decoder(gene_length, gene_length ,graph_list).to(device)\n",
    "\n",
    "optimizer_enc_is = torch.optim.Adam(gene_encoder_is.parameters(), lr=args.lr1)\n",
    "optimizer_enc_com = torch.optim.Adam(gene_encoder_com.parameters(), lr=args.lr1)\n",
    "\n",
    "optimizer_dec2 = torch.optim.Adam(gene_decoder.parameters(), lr=args.lr2)\n",
    "\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "from concurrent.futures import ProcessPoolExecutor,as_completed, ThreadPoolExecutor\n",
    "from multiprocessing import cpu_count\n",
    "\n",
    "import process_pair\n",
    "\n",
    "def compute_gene_sets(graph_list, graph_networkx_list, num_threads=cpu_count()):\n",
    "    common_gene_set = {}\n",
    "    common_gene_overlap = {}\n",
    "    diff_gene_set = {}\n",
    "    diff_gene_neighbor_set = {}\n",
    "\n",
    "    with ThreadPoolExecutor(max_workers=num_threads) as executor:\n",
    "        futures = [\n",
    "            executor.submit(process_pair.process_pair, i, j, graph_list, graph_networkx_list)\n",
    "            for i in range(len(graph_list))\n",
    "            for j in range(len(graph_list))\n",
    "            if i != j\n",
    "        ]\n",
    "\n",
    "        for future in as_completed(futures):\n",
    "            i, j, common_set, common_overlap, diff_set, diff_neighbor_set = future.result()\n",
    "            key = graph_list[i].show_index + graph_list[j].show_index\n",
    "            common_gene_set[key] = common_set\n",
    "            common_gene_overlap[key] = common_overlap\n",
    "            diff_gene_set[key] = diff_set\n",
    "            diff_gene_neighbor_set[key] = diff_neighbor_set\n",
    "\n",
    "    return common_gene_set, common_gene_overlap, diff_gene_set, diff_gene_neighbor_set\n",
    "common_gene_set, common_gene_overlap, diff_gene_set, diff_gene_neighbor_set = compute_gene_sets(graph_list, graph_networkx_list)\n",
    "\n",
    "print(\"finish preprocessing\")\n",
    "print(\"start training\")\n",
    "\n",
    "loss_f = nn.BCEWithLogitsLoss()\n",
    "loss_m = nn.CrossEntropyLoss()\n",
    "from pytorch_metric_learning import losses\n",
    "loss_func = losses.SelfSupervisedLoss(losses.NTXentLoss(temperature = args.temp))\n",
    "\n",
    "lambda_infonce = args.lambdac\n",
    "def penalize_data(z, graph_list,j):\n",
    "    loss = torch.tensor(0.).to(device)\n",
    "    graph_new = graph_list[j]\n",
    "\n",
    "    x = graph_new.x.to(device)\n",
    "    train_pos_edge_index = graph_new.edge_index.to(device)\n",
    "    \n",
    "    x = gene_encoder_is(x, train_pos_edge_index, graph_new.show_index)\n",
    "    z_new = gene_encoder_com(x, train_pos_edge_index, graph_new.show_index)\n",
    "\n",
    "    [index_i, index_j] = common_gene_set[graph.show_index + graph_new.show_index]\n",
    "    if (len(index_i) ==0) or (len(index_j) == 0):\n",
    "        return loss\n",
    "    \n",
    "    z_cor = z[index_i]\n",
    "    z_new_cor = z_new[index_j]\n",
    "    \n",
    "    weight = torch.FloatTensor(common_gene_overlap[graph.show_index + graph_new.show_index]).to(device)\n",
    "    cos_sim = torch.cosine_similarity(z_cor, z_new_cor, axis = 1)*weight\n",
    "\n",
    "    loss += -cos_sim.mean()\n",
    "    \n",
    "    [index_i, index_j] = diff_gene_set[graph.show_index + graph_new.show_index]\n",
    "\n",
    "    if (len(index_i) ==0) or (len(index_j) == 0):\n",
    "        return loss\n",
    "    \n",
    "    opt_index = np.random.choice([i for i in range(len(index_i))], min(100, len(index_i)))\n",
    "    \n",
    "    z_diff = z[index_i[opt_index]]\n",
    "    z_new_diff = z_new[index_j[opt_index]]\n",
    "    \n",
    "    [index_i, index_j] = diff_gene_neighbor_set[graph.show_index + graph_new.show_index]\n",
    "    \n",
    "    z_diff_true =  z[index_i[opt_index]]\n",
    "    z_new_diff_true = z_new[index_j[opt_index]]\n",
    "    \n",
    "    loss += lambda_infonce * loss_func(torch.cat((z_diff,z_new_diff)), torch.cat((z_diff_true,z_new_diff_true)))\n",
    "    return loss\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "97b9a7da-9c09-42bd-9ef1-69c90a12a8a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7049847841262817\n",
      "0.7128649950027466\n",
      "epoch finish\n",
      "epoch finish\n",
      "epoch finish\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/rprojectnb/apoe-signatures/aleshchk/.conda/envs/myenv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/scratch/3289030.1.csgpu/ipykernel_113821/1320484080.py:87: FutureWarning: In the future, the default backend for leiden will be igraph instead of leidenalg.\n",
      "\n",
      " To achieve the future defaults please pass: flavor=\"igraph\" and n_iterations=2.  directed must also be False to work with igraph's implementation.\n",
      "  sc.tl.leiden(adata)\n"
     ]
    }
   ],
   "source": [
    "# Contrastive learning\n",
    "gene_encoder_is.train()\n",
    "gene_encoder_com.train()\n",
    "graph_index_list = [item for item in range(0, len(graph_list))]\n",
    "edge_adj_list = [torch.FloatTensor(cor_list[i].values).to(device) for i in graph_index_list]\n",
    "\n",
    "for epoch in range(args.epoches):\n",
    "    loss = 0.\n",
    "    for i in range(0,len(graph_index_list)):\n",
    "        \n",
    "        optimizer_enc_is.zero_grad(set_to_none=True)\n",
    "        optimizer_enc_com.zero_grad(set_to_none=True)\n",
    "        optimizer_dec2.zero_grad(set_to_none=True)\n",
    "\n",
    "        graph = graph_list[i]\n",
    "\n",
    "        x = graph.x.to(device)\n",
    "        train_pos_edge_index = graph.edge_index.to(device)\n",
    "        edge_adj = edge_adj_list[i]\n",
    "\n",
    "        x = gene_encoder_is(x, train_pos_edge_index,  graph.show_index)\n",
    "        z = gene_encoder_com(x, train_pos_edge_index, graph.show_index)\n",
    "        \n",
    "        adj = torch.matmul(z, z.t())\n",
    "        edge_reconstruct = gene_decoder(adj, graph.show_index)\n",
    "        \n",
    "        loss = loss_f(edge_reconstruct.flatten(), edge_adj.flatten()) \n",
    "\n",
    "        if epoch % 200 ==0:\n",
    "            print(loss.item())\n",
    "\n",
    "        graph_index_list_copy = graph_index_list.copy()\n",
    "        graph_index_list_copy.remove(i)\n",
    "\n",
    "        j = random.sample(graph_index_list_copy, 1)\n",
    "        loss += penalize_data(z, graph_list,j[0]) \n",
    "\n",
    "        del graph\n",
    "        loss.backward()\n",
    "        del loss\n",
    "        \n",
    "        optimizer_enc_is.step()\n",
    "        optimizer_enc_com.step()\n",
    "        optimizer_dec2.step()\n",
    "        \n",
    "    print(\"epoch finish\")\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "emb_list = []\n",
    "gene_list = []\n",
    "tissue_list = []\n",
    "\n",
    "# inference step\n",
    "gene_encoder_is.eval()\n",
    "gene_encoder_com.eval()\n",
    "with torch.no_grad():\n",
    "    for i in range(0,len(graph_list)):\n",
    "        graph = graph_list[i]\n",
    "        x = graph.x.to(device)\n",
    "        train_pos_edge_index = graph.edge_index.long().to(device)\n",
    "        \n",
    "        x = gene_encoder_is(x, train_pos_edge_index,  graph.show_index)\n",
    "        z = gene_encoder_com(x, train_pos_edge_index, graph.show_index)\n",
    "        \n",
    "        emb_list.append(z.cpu().numpy())\n",
    "        gene_list.append(graph.gene_list)\n",
    "        tissue_list.append([graph.show_index for j in range(len(x))])\n",
    "\n",
    "adata = sc.AnnData(np.concatenate(emb_list))\n",
    "\n",
    "adata.obs['gene'] = np.concatenate(gene_list)\n",
    "adata.obs['tissue'] = np.concatenate(tissue_list)\n",
    "\n",
    "sc.pp.neighbors(adata, use_rep='X')\n",
    "sc.tl.umap(adata)\n",
    "\n",
    "tissue_list1 = []\n",
    "for i in list(set(adata.obs['tissue'])):\n",
    "    tissue_list1.append(list(adata[adata.obs['tissue'] == i].obs['gene']))\n",
    "\n",
    "common_gene_list = set(tissue_list1[0]).intersection(*tissue_list1[1:])\n",
    "\n",
    "adata.obs['displaygene']= [True if i in common_gene_list else False for i in adata.obs['gene']]\n",
    "adata.obs['displaygene']  = adata.obs['displaygene'].astype('category')\n",
    "\n",
    "sc.tl.leiden(adata)\n",
    "\n",
    "adata.obs['tissue_new'] = [i.split(\"__\")[0] for i in adata.obs['tissue']]\n",
    "\n",
    "adata.write_h5ad(args.savepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "94847f89-4ad4-466b-b032-d1d1b98a0468",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sc.pp.neighbors(adata, use_rep='X')\n",
    "#sc.tl.umap(adata)\n",
    "adata.obs['tissue']\n",
    "tissue_list = {\"heart\":['rna', \"spatial\"]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5be17a5d-b647-4b50-b883-8030a5eb2bc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rna\n",
      "(1000, 1000)\n",
      "spatial\n",
      "(1000, 1000)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/3289030.1.csgpu/ipykernel_113821/389374859.py:43: ImplicitModificationWarning: Setting element `.obsm['X_emb']` of view, initializing view as actual.\n",
      "  adata_new.obsm['X_emb'] = adata_new.X\n",
      "/scratch/3289030.1.csgpu/ipykernel_113821/389374859.py:153: FutureWarning: In function `silhouette_batch`, argument `group_key` was renamed to `label_key`.\n",
      "  asw = calculate_common_asw(adata)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean silhouette per group:        silhouette_score\n",
      "group                  \n",
      "0              0.967297\n",
      "1              0.818709\n",
      "11             0.626797\n",
      "2              0.866966\n",
      "3              0.969360\n",
      "4              0.887299\n",
      "5              0.928222\n",
      "6              0.899034\n",
      "7              0.875465\n",
      "8              0.909301\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/3289030.1.csgpu/ipykernel_113821/389374859.py:89: ImplicitModificationWarning: Setting element `.obsm['X_emb']` of view, initializing view as actual.\n",
      "  adata_new.obsm['X_emb'] = adata_new.X\n",
      "/rprojectnb/apoe-signatures/aleshchk/.conda/envs/myenv/lib/python3.12/site-packages/scib/metrics/graph_connectivity.py:56: FutureWarning: pandas.value_counts is deprecated and will be removed in a future version. Use pd.Series(obj).value_counts() instead.\n",
      "  tab = pd.value_counts(labels)\n",
      "/rprojectnb/apoe-signatures/aleshchk/.conda/envs/myenv/lib/python3.12/site-packages/scib/metrics/graph_connectivity.py:56: FutureWarning: pandas.value_counts is deprecated and will be removed in a future version. Use pd.Series(obj).value_counts() instead.\n",
      "  tab = pd.value_counts(labels)\n",
      "/rprojectnb/apoe-signatures/aleshchk/.conda/envs/myenv/lib/python3.12/site-packages/scib/metrics/graph_connectivity.py:56: FutureWarning: pandas.value_counts is deprecated and will be removed in a future version. Use pd.Series(obj).value_counts() instead.\n",
      "  tab = pd.value_counts(labels)\n",
      "/rprojectnb/apoe-signatures/aleshchk/.conda/envs/myenv/lib/python3.12/site-packages/scib/metrics/graph_connectivity.py:56: FutureWarning: pandas.value_counts is deprecated and will be removed in a future version. Use pd.Series(obj).value_counts() instead.\n",
      "  tab = pd.value_counts(labels)\n",
      "/rprojectnb/apoe-signatures/aleshchk/.conda/envs/myenv/lib/python3.12/site-packages/scib/metrics/graph_connectivity.py:56: FutureWarning: pandas.value_counts is deprecated and will be removed in a future version. Use pd.Series(obj).value_counts() instead.\n",
      "  tab = pd.value_counts(labels)\n",
      "/rprojectnb/apoe-signatures/aleshchk/.conda/envs/myenv/lib/python3.12/site-packages/scib/metrics/graph_connectivity.py:56: FutureWarning: pandas.value_counts is deprecated and will be removed in a future version. Use pd.Series(obj).value_counts() instead.\n",
      "  tab = pd.value_counts(labels)\n",
      "/rprojectnb/apoe-signatures/aleshchk/.conda/envs/myenv/lib/python3.12/site-packages/scib/metrics/graph_connectivity.py:56: FutureWarning: pandas.value_counts is deprecated and will be removed in a future version. Use pd.Series(obj).value_counts() instead.\n",
      "  tab = pd.value_counts(labels)\n",
      "/rprojectnb/apoe-signatures/aleshchk/.conda/envs/myenv/lib/python3.12/site-packages/scib/metrics/graph_connectivity.py:56: FutureWarning: pandas.value_counts is deprecated and will be removed in a future version. Use pd.Series(obj).value_counts() instead.\n",
      "  tab = pd.value_counts(labels)\n",
      "/rprojectnb/apoe-signatures/aleshchk/.conda/envs/myenv/lib/python3.12/site-packages/scib/metrics/graph_connectivity.py:56: FutureWarning: pandas.value_counts is deprecated and will be removed in a future version. Use pd.Series(obj).value_counts() instead.\n",
      "  tab = pd.value_counts(labels)\n",
      "/rprojectnb/apoe-signatures/aleshchk/.conda/envs/myenv/lib/python3.12/site-packages/scib/metrics/graph_connectivity.py:56: FutureWarning: pandas.value_counts is deprecated and will be removed in a future version. Use pd.Series(obj).value_counts() instead.\n",
      "  tab = pd.value_counts(labels)\n",
      "/rprojectnb/apoe-signatures/aleshchk/.conda/envs/myenv/lib/python3.12/site-packages/scib/metrics/graph_connectivity.py:56: FutureWarning: pandas.value_counts is deprecated and will be removed in a future version. Use pd.Series(obj).value_counts() instead.\n",
      "  tab = pd.value_counts(labels)\n",
      "/rprojectnb/apoe-signatures/aleshchk/.conda/envs/myenv/lib/python3.12/site-packages/scib/metrics/graph_connectivity.py:56: FutureWarning: pandas.value_counts is deprecated and will be removed in a future version. Use pd.Series(obj).value_counts() instead.\n",
      "  tab = pd.value_counts(labels)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.13564668769716093\n",
      "0.0\n",
      "0.06976744186046513\n",
      "0.0803571428571429\n",
      "0.04471544715447151\n",
      "0.0625\n",
      "0.04878048780487809\n",
      "0.015625\n",
      "0.04489795918367345\n",
      "0.04166666666666663\n",
      "0.0\n",
      "0.16666666666666663\n",
      "finish one cluster\n",
      "finish one cluster\n",
      "finish one cluster\n",
      "finish one cluster\n",
      "finish one cluster\n",
      "finish one cluster\n",
      "finish one cluster\n",
      "finish one cluster\n",
      "finish one cluster\n",
      "finish one cluster\n",
      "finish one cluster\n",
      "finish one cluster\n",
      "                      0\n",
      "ASW            0.874845\n",
      "AUC            0.556394\n",
      "GC             0.919824\n",
      "Common ratio   0.064000\n",
      "share overlap  0.058530\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ASW</th>\n",
       "      <td>0.874845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AUC</th>\n",
       "      <td>0.556394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GC</th>\n",
       "      <td>0.919824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Common ratio</th>\n",
       "      <td>0.064000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>share overlap</th>\n",
       "      <td>0.058530</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      0\n",
       "ASW            0.874845\n",
       "AUC            0.556394\n",
       "GC             0.919824\n",
       "Common ratio   0.064000\n",
       "share overlap  0.058530"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import scanpy as sc\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "\n",
    "import scib\n",
    "\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "\n",
    "# construct graph batch based on simulation results\n",
    "graph_list = []\n",
    "cor_list = {}\n",
    "label_list = [] \n",
    "count = 0\n",
    "for tissue in tissue_list.keys():\n",
    "    for i in tissue_list[tissue]:\n",
    "        print(i)\n",
    "        pathway_count = \"/projectnb/cs598/projects/singleCell/data/heart_\" + i + \"_expression.csv\"\n",
    "        pathway_matrix = \"/projectnb/cs598/projects/singleCell/data/heart_\" + i + \"_pvalue.csv\"\n",
    "        correlation = pd.read_csv(pathway_matrix, sep=\",\", index_col=0)\n",
    "        cor_list[tissue +\"__\" + str(i)] = correlation\n",
    "\n",
    "        print(correlation.shape)\n",
    "\n",
    "        label_list.append(tissue +\"__\" + str(i))\n",
    "        \n",
    "        count +=1\n",
    "\n",
    "# sigmoid function\n",
    "def sigmoid(x):\n",
    "    return 1/(1 + np.exp(-x))\n",
    "\n",
    "# metric 1: Calculate gene ASW\n",
    "def calculate_common_asw(adata):\n",
    "    tissue_list = []\n",
    "    for i in list(set(adata.obs['tissue'])):\n",
    "        tissue_list.append(list(adata[adata.obs['tissue'] == i].obs['gene']))\n",
    "        \n",
    "    common_gene_list = set(tissue_list[0]).intersection(*tissue_list[1:])\n",
    "    adata_new = adata[[True if i in common_gene_list else False for i in adata.obs['gene']]]\n",
    "    adata_new.obsm['X_emb'] = adata_new.X\n",
    "    \n",
    "    result = scib.metrics.silhouette_batch(adata_new, batch_key='tissue', group_key='leiden', embed='X_emb')\n",
    "    \n",
    "    return result    \n",
    "\n",
    "\n",
    "# metric 2: Calculate normalized AUC\n",
    "def calculate_AUC(adata, cor_list):\n",
    "    tissue_list = list(set(cor_list.keys()))\n",
    "    \n",
    "    result = 0\n",
    "    for i in tissue_list:\n",
    "        adata_new = adata[adata.obs['tissue'] == i]\n",
    "\n",
    "        normed_matrix = normalize(adata_new.X, axis=1)\n",
    "        rec_matrix = sigmoid(normed_matrix@normed_matrix.T).flatten()\n",
    "        cor_matrix = cor_list[i].values.flatten()\n",
    "        result += roc_auc_score(cor_matrix, rec_matrix)\n",
    "    \n",
    "    result = result/len(tissue_list)\n",
    "    return result    \n",
    "\n",
    "# metric 3: Calculate gene LISI\n",
    "def calculate_iLISI(adata):\n",
    "    tissue_list = []\n",
    "    for i in list(set(adata.obs['tissue'])):\n",
    "        tissue_list.append(list(adata[adata.obs['tissue'] == i].obs['gene']))\n",
    "        \n",
    "    common_gene_list = set(tissue_list[0]).intersection(*tissue_list[1:])\n",
    "    adata_new = adata[[True if i in common_gene_list else False for i in adata.obs['gene']]]\n",
    "    adata_new.obsm['X_emb'] = adata_new.X\n",
    "    \n",
    "    result = scib.metrics.ilisi_graph(adata_new, batch_key=\"tissue\", type_=\"embed\")\n",
    "    \n",
    "    return result   \n",
    "\n",
    "# metric 4: Calculate gene GC\n",
    "def calculate_graph_connectivity(adata):\n",
    "    tissue_list = []\n",
    "    for i in list(set(adata.obs['tissue'])):\n",
    "        tissue_list.append(list(adata[adata.obs['tissue'] == i].obs['gene']))\n",
    "        \n",
    "    common_gene_list = set(tissue_list[0]).intersection(*tissue_list[1:])\n",
    "    adata_new = adata[[True if i in common_gene_list else False for i in adata.obs['gene']]]\n",
    "\n",
    "    adata_new.obsm['X_emb'] = adata_new.X\n",
    "    \n",
    "    result = scib.metrics.graph_connectivity(adata_new,'leiden')\n",
    "    \n",
    "    return result    \n",
    "\n",
    "# metric 5: Calculate commom gene propertion\n",
    "def calculate_common_gene_propertion(adata):\n",
    "    full_score = 0\n",
    "    for i in list(set(adata.obs['leiden'])):\n",
    "        adata_new = adata[adata.obs['leiden'] == i]\n",
    "        \n",
    "        gene_list = set(adata_new.obs['gene'])\n",
    "        \n",
    "        prop = 1 - len(gene_list)/len(adata_new.obs['gene'])\n",
    "        print(prop)\n",
    "        \n",
    "        full_score += len(adata_new)/len(adata) * prop\n",
    "        \n",
    "    return full_score\n",
    "\n",
    "# Helper function: Jaccard score for genes in different graphs.\n",
    "def calculate_overlap(G1,G2,g1,g2):\n",
    "    G1_neg = list(G1.neighbors(g1))\n",
    "    G2_neg = list(G2.neighbors(g2))\n",
    "    \n",
    "    overlap_score = len(set(G1_neg).intersection(set(G2_neg)))/len(set(G1_neg).union(set(G2_neg)))\n",
    "    \n",
    "    return overlap_score\n",
    "\n",
    "# metric 6: Calculate neighbor genes' overlap\n",
    "def calculate_common_neighbor_ovarlap(adata, cor_list):\n",
    "    output_value = 0\n",
    "    for i in list(set(adata.obs['leiden'])):\n",
    "        adata_new = adata[adata.obs['leiden'] == i]\n",
    "        \n",
    "        tissue_list = list(adata_new.obs['tissue'])\n",
    "        gene_list = list(adata_new.obs['gene'])\n",
    "        \n",
    "        overlap_value = 0\n",
    "        dim_value = 0\n",
    "        for num1,item1 in enumerate(gene_list):\n",
    "            for num2,item2 in enumerate(gene_list):\n",
    "                t1 = tissue_list[num1]\n",
    "                t2 = tissue_list[num2]\n",
    "                if t1 != t2:\n",
    "                    g1 = graph_list[t1]\n",
    "                    g2 = graph_list[t2]\n",
    "                    temp_overlap = calculate_overlap(g1,g2,item1,item2)\n",
    "                    overlap_value += temp_overlap\n",
    "                    dim_value += 1.0\n",
    "                \n",
    "        print(\"finish one cluster\")\n",
    "        \n",
    "        if dim_value == 0:\n",
    "            overlap_value = 0\n",
    "        else:\n",
    "            overlap_value = overlap_value/dim_value\n",
    "        output_value += overlap_value*len(adata_new)/len(adata)\n",
    "        \n",
    "    return output_value\n",
    "\n",
    "# Integrated function for metric calculation\n",
    "def calculate_metric(adata, cor_list):\n",
    "    asw = calculate_common_asw(adata)\n",
    "    AUC = calculate_AUC(adata, cor_list)\n",
    "    #ilisi = calculate_iLISI(adata)\n",
    "    gc = calculate_graph_connectivity(adata)\n",
    "    \n",
    "    \n",
    "    ratio = calculate_common_gene_propertion(adata)\n",
    "    \n",
    "    ovl = calculate_common_neighbor_ovarlap(adata, cor_list)\n",
    "    \n",
    "    #df = pd.DataFrame(np.array([asw,AUC,ilisi,gc,ratio, ovl]))\n",
    "    df = pd.DataFrame(np.array([asw, AUC,gc,ratio, ovl]))\n",
    "    #df.index = ['ASW', 'AUC', 'iLISI', 'GC', 'Common ratio', 'share overlap']\n",
    "    df.index = ['ASW', 'AUC', 'GC', 'Common ratio', 'share overlap']\n",
    "    print(df)\n",
    "    return df\n",
    "\n",
    "# run the benchmark process\n",
    "graph_list = {}\n",
    "for i in cor_list.keys():\n",
    "    graph_list[i] = nx.from_pandas_adjacency(cor_list[i])\n",
    "\n",
    "# run the benchmark\n",
    "seed = 0\n",
    "adata = sc.read_h5ad(\"heart_umi_m_musegnn.h5ad\")\n",
    "calculate_metric(adata, cor_list)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
